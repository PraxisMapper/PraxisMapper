Requirements: 16+GB RAM (Will still page frequently with the most complicated areas, but they all finish in ~45 minutes in the worst case with an SSD)
Global database is current ~45GB, would want at least 64GB RAM for a DB server to hold everything in memory.

Important Things to Remember:
* This can function as a MapTile provider. The work to draw fully accurate mapTiles has been done. But primarily we want to be a game server.
-- as much as MapTiles aren't the game itself, MapTiles are the primary thing people notice.
* It's OK to do something that's already been done your own way. It's important to have an option that isn't under corporate control.
* We use PlusCodes instead of S2 cells.
-- Plus Codes are more human-friendly, in that you could remember 4-10 digits for a certain area. S2 cells are much harder to remember for a person. They're designed for indexing in a DB faster.
-- They're square along cardinal directions. S2 cells are rhombus-shaped.
-- A human can figure out how to navigate between 2 PlusCodes with some practice. This is possible on S2 cells, but requires much, much more effort.

How to run this:

1) Create and configure your DB (SQL Server, MariaDB, or PostgreSQL) for this app. Update connection string in Larry/ParserSettings.cs, create DB by running "Larry -createDB"

2) Download the latest .osm.pbf files to use from Geofabrik.de (or another OSM mirror) and unzip them to the appropriate folder.
--Use the smallest data file/set reasonable for development and testing. Files take up at least 10x the amount of RAM the filesize on disk. Usually more.
--State-level is usually reasonable. Some specific areas have issues processing because of the amount of detail on some things. (Norway and Quebec have a ton of water entries in tiny details, for example)
--the apps can filter down a file to a smaller area, for cases where a reasonable-sized file eats more ram than we have.

3) Assuming this is a first setup, Run Larry with these arguments in order (separately is ideal, but could do all at once with enough RAM):
-createDB (Creates DB according to the connection string.)
-loadPbfsToDb (if you have the RAM to handle each individual file sequentially, this is the fastest process)
OR
-loadPbfsToJson
-loadJsonToDb
for a two-step process that makes later work faster.

Functions to replace entries in-line exist, but currently expect you to have used loadPbfsToJson.

Server-side, assuming you want an AWS node running Windows Server.:
Set AWS Security rules to only allow RDP from a narrow range (single IP if possible, /24 block for ISP if not.)
deploy API app to its own folder, make sure IIS is pointing at folder with .exe and .dll files. Turn off Managed Code. 
Upload database file to S3, copy file to server (instructions how TBD)
Attach database to Sql Server (with or without SSMS installed? how TBD)

test API endpoint. /mapdata/test should return "OK" if IIS is up and running. actual data endpoint should return stuff with valid inputs if DB is running and connected correctly.
Should return something on error so I can figure out why a call doesnt work. I also think I need to upload a new DB to the server

Slippy map tiles are in!
Go to /Slippy to view a nice, web style map viewer powered by PraxisMapper!

Set these as the arguments for Larry to redo everything at once: (Assuming you have the ram to process your PBF files in question.)
-cleanDB -resetPbf -resetJson -loadPbfsToDb -removeDupes

Notes:
Database side:
Querying spatial data:
DECLARE @p1 geography
  SET @p1 = geography::STGeomFromText('POINT (-53.235222 21.536760)', 4326)
  SELECT * FROM MapData
  WHERE @p1.STWithin(place) = 1


 Test Functions:
 -AnalyzeAllAreas
 ** this reads every cell on the globe for info, saves it to a new DB table.
 ** For evaluating if its better to calculate the end results once and just save that instead of looking them up every time and caching in memory.