Note: all results are on Windows 10 hosting DB and app on same machine unless otherwise notes
TODO: run tests on Docker Linux setup, compare results.

PerformanceInfoEFCoreVsSproc 9/30/2020:
PerformanceTracker EntityFrameworkCore total  /average speed: 1793 / 17ms.
PerformanceTracker EntityFrameworkCore NoChangeTracking total /average speed: 80 / 0ms.
PerformanceTracker Sproc total / average speed: 71 / 0ms.
Decision: use entities with changetracking off for performance tracker. Keeps DB access consistent and in EFCore.

S2VsPlusCode 9/30/2020:
PlusCode conversion total / average time: 10 / 0 ms
S2 conversion total / average time: 7 / 0 ms
Decision: Sticking to pluscodes. Can do 1000 conversion in 1ms, and still drastically more useful for human-facing stuff than S2 cells.

SplitAreaValues 9/30/2020: (using more local data)
Pulling 223 places in 6-cell took 2029ms
dividing map by 1 took 5108 ms
dividing map by 2 took 1554 ms
dividing map by 4 took 1177 ms
dividing map by 8 took 696 ms
dividing map by 10 took 721 ms
dividing map by 20 took 376 ms
dividing map by 25 took 316 ms
dividing map by 32 took 318 ms
dividing map by 40 took 270 ms
dividing map by 80 took 373 ms
dividing map by 100 took 464 ms
Decision: 40 remains the fastest factor to split a 6cell by.
Additional performance increases were gained during testing, but this function's results stayed proportionate. These are the final results. 

TestSpeedChangeByArea() 10/1/2020: (Using Ohio data only, didn't have roads/buildings)
First loop has some warmup time.
8-code search time is 2111ms
6-code search time is 45ms
4-code search time is 661ms
2-code search time is 2981ms
8-code search time is 1ms
6-code search time is 5ms
4-code search time is 363ms
2-code search time is 2815ms
8-code search time is 1ms
6-code search time is 7ms
4-code search time is 358ms
2-code search time is 3284ms
8-code search time is 1ms
6-code search time is 11ms
4-code search time is 363ms
2-code search time is 2602ms
8-code search time is 1ms
6-code search time is 36ms
4-code search time is 473ms
2-code search time is 3027ms
Average 8-code search time is 423ms
6-code search time would be 169200 linearly, is actually 104 (1626x faster)
Average 6-code search time is 20ms
4-code search time would be 8320 linearly, is actually 2218 (3x faster)
Average 4-code search time is 443ms
2-code search time would be 177440 linearly, is actually 14709 (12x faster)
Average 2-code search time is 2941ms
Decision: pulling 6-code data seems to provide the best ratio of data to time consumed. 
Note: This was run on partial server data. Re-run with global data in DB for more accurate results.

TestSpeedChangeByArea() 10/4/2020: (Using global data, with admin boundaries) (2-cells took over 30 seconds to load, excluding those)
First loop has some warmup time.
8-code search time is 1690ms
6-code search time is 77ms
4-code search time is 2495ms
8-code search time is 2ms
6-code search time is 44ms
4-code search time is 2440ms
8-code search time is 9ms
6-code search time is 56ms
4-code search time is 2630ms
8-code search time is 2ms
6-code search time is 50ms
4-code search time is 2504ms
8-code search time is 2ms
6-code search time is 58ms
4-code search time is 2317ms
Average 8-code search time is 341ms
6-code search time would be 136400 linearly, is actually 285 (478x faster)
Average 6-code search time is 57ms
4-code search time would be 22800 linearly, is actually 12386 (1x faster)
Average 4-code search time is 2477ms
Decision: Yes, Global data increases search times, noticeably on the 6-cell (~10x slower) and 4-cell (~6x slower) calls
Still, 6-code cells seem to provide the best data:time ratio. Users would not usually notice a 50ms wait, they would feel a 2300ms wait.


TestMapDataAbbrev() 10/1/2020
Full data time took 244ms
short data time took 97ms
Full data time took 19ms
short data time took 110ms
Full data time took 25ms
short data time took 72ms
Full data time took 20ms
short data time took 75ms
Full data time took 17ms
short data time took 64ms
Decision: the Select() transform adds processing time. We will not use the shorthand records.

TestGetPlacesPerf() 10/1/2020:
6code- Tracking: 2074ms VS NoTracking: 37ms VS Precompiled: 37ms
4code- Tracking: 569ms VS NoTracking: 399ms VS Precompiled: 448ms
6code- Tracking: 6ms VS NoTracking: 6ms VS Precompiled: 7ms
4code- Tracking: 344ms VS NoTracking: 462ms VS Precompiled: 461ms
6code- Tracking: 6ms VS NoTracking: 5ms VS Precompiled: 16ms
4code- Tracking: 356ms VS NoTracking: 369ms VS Precompiled: 521ms
6code- Tracking: 5ms VS NoTracking: 17ms VS Precompiled: 5ms
4code- Tracking: 404ms VS NoTracking: 369ms VS Precompiled: 426ms
6code- Tracking: 17ms VS NoTracking: 5ms VS Precompiled: 7ms
4code- Tracking: 412ms VS NoTracking: 448ms VS Precompiled: 451ms
Decision: Nothing here seems to make a significant different, though precompiling the query seems slower than expected.

TestMultiPassVsSinglePass() 10/7/2020:
Reading all types took 21552ms.
Reading water type took 21115ms.
Reading cemetery type took 20948ms.
Decision: Doing one pass takes the same time as doing multiple. Doing multiple passes takes up less RAM.
May consider doing multiple passes only on problem files, but should stick to single pass otherwise.

ConcurrentTest 10/13/2020
Both data sources populated. Starting test.
Standard list took 374785 ticks (37ms)
ConcurrentBag took 46264 ticks (4ms)
However, real-world testing shows ConcurrentBag<T> makes processing Ohio a minute slower, makes RAM contents vary a lot, never fully utilizes the CPU.
Because these use a ton of RAM, and I'm trying to work out how to limit RAM usage on the most problematic files, this won't be used.

TestIntersectsPreparedVsNot 1/21/21
Loading data for Intersect performance test.
Cell6 Data loaded.
Normal geometries search took 5957012 ticks (595ms)
Prepped Cell8 & Normal geometries search took 1780437 ticks (178ms)
Prepped List & Normal Cell8 search took 4779015 ticks (477ms), 1903363 ticks were prepping list
Decision: The correct option is to have 1 PreparedGeometry instance (the PlusCode cell we're looking at) do an Intersects() check on a list of places.

TestRasterVsVector 1/24/21:
Loading data for Raster Vs Vector performance test. 400 cell8 test.
Raster performance:5537ms
Vector performance:622ms
Loading data for Raster Vs Vector performance test. 400 cell10 test.
Raster performance:47ms
Vector performance:26ms
Decision: The new vector logic draws prettier tiles faster at essentially every scale. Twice as fast on small tiles, and quickly pulls ahead on larger ones.
I'll switch over to it. I may want to figure out some styling rules that can be defined in code (probably on AreaType class) that will let my maps become more flexible.
And I wouldn't have to be limited to drawing to a PlusCode size for pixels.

ImageSharpVsSkiaSharp 3/4/21:
(zoom 12)
Loading data for ImageSharp vs SkiaSharp performance test
ImageSharp performance:1262ms
SkiaSharp performance:518ms
(zoom 15)
Loading data for ImageSharp vs SkiaSharp performance test
ImageSharp performance:452ms
SkiaSharp performance:103ms
Decision: SkiaSharp wins. 2-4x faster. Looks identical. Simpler customization options.

Re-evaluating DB performance 5/19/21:
Starting SqlServer performance test.
Loading Delaware data for consistency.
Saved baseline data to DB in 00:01:19.5911684
10,000 random reads done in 5585ms
Loaded all Delaware items in 1756ms
10,000 random writes done in 9322ms
Starting MariaDb performance test.
Loading Delaware data for consistency.
Saved baseline data to DB in 00:01:41.0343120
10,000 random reads done in 12966ms
Loaded all Delaware items in 725ms
10,000 random writes done in 6664ms
Starting PostgreSQL performance test.
Loading Delaware data for consistency.
Saved baseline data to DB in 00:01:09.2225004
10,000 random reads done in 6119ms
Loaded all Delaware items in 1162ms
10,000 random writes done in 6334ms
Summary:
MS SQL: 1:19,  5585, 1756, 9322
Maria:  1:41, 12966,  725, 6664
PgSQL:  1:09,  6119, 1162, 6334 
(all 3 databases were run from the same hard drive on the same PC, so there shouldn't be too much difference between these results based on underlying hardware.)
Conclusion: MariaDB is the slowest on the most common tasks, but seems to be the fastest on big reads as well.
MSSQL and PostgreSQL are pretty close in performance. Maybe I should migrate towards PostgreSQL after all.

TagParser benchmarking 5/22/21:
perf-testing tag parser options
1000 empty lists run in 9590 ticks with default (0ms avg)
1000 single entry default-match lists run in 1542570 ticks (0.154ms avg)
1000 8-tag match-water lists run in 2343411 ticks(0.234ms avg)
1000 8-tag default match lists run in 2316723 ticks(0.231ms avg)
1000 40-tag default match lists run in 23529037 ticks(2.352ms avg)
Conclusion: the TagParser engine is sufficiently fast to use. This is about twice as fast as the previous logic in that loop.

Investigating if cropping area is still necessary 5/24/21: (on a Cell6 and a Cell4)
perf-testing cropping StoredWay objects before drawing
Loaded 751 objects for test
Uncropped tile drawn in 121ms
Geometry objects cropped in 534ms
Cropped tile drawn in 50ms
perf-testing cropping StoredWay objects before drawing
Loaded 370408 objects for test
Uncropped tile drawn in 8293ms
Geometry objects cropped in 16418ms
(//25 geometry errors trimmed)
Cropped tile drawn in 7463ms
Conclusion: Cropping geometry objects is no longer a performance boost. I think this changed with the swap from ImageSharp to SkiaSharp for drawing logic.

TagParser benchmarks with conversion to dictionary:
perf-testing tag parser options
100000 empty lists run in 931941 ticks with default (0.00093ms avg)
100000 single entry default-match lists run in 80838617 ticks (0.08083ms avg)
100000 8-tag match-water lists run in 20490744 ticks(0.02049ms avg)
100000 8-tag default match lists run in 85084616 ticks(0.08508ms avg)
100000 48-tag default match lists run in 128137788 ticks(0.12813ms avg)
Using dictionary instead of list:
100000 empty dicts run in 611362 ticks with default (0.00061ms avg)
100000 single entry default-matchdicts run in 76445437 ticks (0.07644ms avg)
100000 8-tag match-default dicts run in 75155828 ticks(0.07515ms avg)
100000 9-tag match-water dicts run in 8077064 ticks(0.00807ms avg)
100000 45-tag match-default dicts run in 71670868 ticks(0.07167ms avg)
100000 46-tag match-water dicts run in 7806726 ticks(0.0078ms avg)
Conclusion: The new codepath is much faster than the original for over 8 tags. Factoring in time converting a list to a dictionary, it looks like this breaks even at worse.
The average # of tags per element is ~3 per https://taginfo.openstreetmap.org/reports/database_statistics
On average, all entries are faster by at least 10%. Some are 2x faster.

Comparing my PBF reader versus OSMSharp stock (Lake Erie):
Starting to load one relation from file.
Indexing file...
Found 3241 blocks. 4 relation blocks and 350 way blocks.
File indexed in 00:00:08.1569974
Current stats:
Blocks completed this run: 0
Long-running/writing pending: 0
Processing tasks: 0
Processing completed at 9/22/2021 9:21:47 AM, session lasted 00:00:11.1531879
Customized PBF reader loaded 1 area in 00:00:11.2660481
Original PBF reader loaded 1 area in 00:00:51.5567605
Conclusion: Even with indexing, my code is much faster. I knew it was, but I wanted to see a difference. 5x faster for a single area.
Doing multiple areas would reduce that gap, but my code uses much less RAM in that case.

Rematch: Imagesharp vs Skia: 1/27/22, Release builds, 260 tiles from downtown. (Tablet)
Average Skia time:0.06538461538461539
Average ImageSharp time:7.046153846153846
(using JPEG instead of PNG):
Average Skia time:0.15384615384615385
Average ImageSharp time:6.415384615384616
(removing transparent areas in MapTileSupport)
Average Skia time:0.20384615384615384
Average ImageSharp time:1.0076923076923077
(repeat of above)
Average Skia time:0.057692307692307696
Average ImageSharp time:0.8884615384615384
(not cropping areas to maptile):
Average Skia time:0.075
Average ImageSharp time:0.485
Conclusion: this is very swing-y, but confirms ImageSharp is slower. BUT on a scale that's entirely acceptable. Best performance is 5x slower
This probably means most of the actual time for making a maptile is done elsewhere in my code, and adding 7ms per tile (in the worst general case) to that is probably not awful by itself

Re-Rematch: Imagesharp vs Skia: 2/13/22, Release builds, 260 tiles from downtown. (PC, not Tablet)
(NOTE: now in ticks not ms, for more reasonable comparison results.)
Average Skia time:4656.496153846154
Average Skia tiles per second:2147.5374765939064
Average ImageSharp time:16564.580769230768
Average ImageSharp tiles per second:603.6977415435298
(back to all 400 tiles in the Cell6 selected.)
Average Skia time:4530.435
Average Skia tiles per second:2207.2935601106733
Average ImageSharp time:12359.52
Average ImageSharp tiles per second:809.0929097570132
(repeat)
Average Skia time:4631.085
Average Skia tiles per second:2159.3211957888916
Average ImageSharp time:12598.73
Average ImageSharp tiles per second:793.7307966755379
Summary: ImageSharp is 2.75x slower (40% of Skiasharp's speed), which is totally reasonable compared to the best-case of 5x above. I need to get it on a T4G instance to see how perf works out.